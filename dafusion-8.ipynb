{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-YPt63OC7mRq","executionInfo":{"status":"ok","timestamp":1684030215026,"user_tz":300,"elapsed":773,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}},"outputId":"5232e78d-27b7-4b1f-cfae-f74690c9db04"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"vRdwFtuzXtgl","executionInfo":{"status":"ok","timestamp":1684030054010,"user_tz":300,"elapsed":4434,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","import time\n","import tqdm\n","import shutil\n","import torch.nn as nn\n","import torchvision.models as  models\n","from torch.utils.data import DataLoader, ConcatDataset\n","import torchvision.datasets.voc as voc\n","import torch.optim as optim\n","from PIL import Image\n","from glob import glob\n","from tqdm import tqdm\n","from torchvision import transforms\n","from torchvision.models import resnet18\n","import torch.utils.model_zoo as model_zoo\n","import xml.etree.cElementTree as ET"]},{"cell_type":"code","source":["os.chdir('/content/drive/MyDrive')"],"metadata":{"id":"mJ-lc-OTfy0Q","executionInfo":{"status":"ok","timestamp":1684030068567,"user_tz":300,"elapsed":88,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!unzip pascal-aug-20230514T005135Z-001.zip"],"metadata":{"id":"Mlj_KfP3wveP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684027317266,"user_tz":300,"elapsed":3485,"user":{"displayName":"Rishi Garg","userId":"14881396349734860395"}},"outputId":"99a84aa9-1512-441c-f003-1f6bdf791dd5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  pascal-aug-20230514T005135Z-001.zip\n","replace pascal-aug/pascal-0-4/VOCdevkit/VOC2012/ImageSets/Main/train.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100,"status":"ok","timestamp":1684030239641,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"},"user_tz":300},"id":"aQ22btbUZu8E","outputId":"d92d540f-ae9e-4fc5-f903-43d1b6ba8fef"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7ff8bc5ca070>"]},"metadata":{},"execution_count":5}],"source":["data_dir = '/content/drive/MyDrive/pascal'\n","aug_dir = '/content/drive/MyDrive/CS444Project/Project/data/pascal-aug/pascal-0-8'\n","ckpt_dir = '/content/drive/MyDrive/CS444Project/Project/checkpoints'\n","object_categories = ['aeroplane', 'bicycle', 'bird', 'boat',\n","                     'bottle', 'bus', 'car', 'cat', 'chair',\n","                     'cow', 'diningtable', 'dog', 'horse',\n","                     'motorbike', 'person', 'pottedplant',\n","                     'sheep', 'sofa', 'train', 'tvmonitor']\n","num_classes = len(object_categories)\n","batch_size = 32\n","resnet_lr = 1e-5\n","fc_lr = 5e-3\n","num_epochs = 25\n","\n","mean = [0.457342265910642, 0.4387686270106377, 0.4073427106250871]\n","std = [0.26753769276329037, 0.2638145880487105, 0.2776826934044154]\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","np.random.seed(1902)\n","torch.manual_seed(1902)"]},{"cell_type":"markdown","metadata":{"id":"wJ-uygocbOw8"},"source":["## Data Pipeline\n","\n","Download the PASCAL VOC dataset and create train and val data loaders."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"bnu_0d_VY3_5","executionInfo":{"status":"ok","timestamp":1684030241416,"user_tz":300,"elapsed":95,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"outputs":[],"source":["class PascalVOC_Dataset(voc.VOCDetection):\n","    \"\"\"Pascal VOC Detection Dataset\"\"\"\n","    def __init__(self, root, image_set='train', download=False, transform=None, target_transform=None):\n","        super().__init__(root, image_set=image_set, download=download, transform=transform, target_transform=target_transform)\n","    \n","    def __getitem__(self, index):\n","        return super().__getitem__(index)\n","    \n","    def __len__(self):\n","        return len(self.images)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"6qNEJbp6aCjE","executionInfo":{"status":"ok","timestamp":1684030241897,"user_tz":300,"elapsed":146,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"outputs":[],"source":["def encode_labels(target):\n","    \"\"\"Encode multiple labels using 1/0 encoding\"\"\"\n","    ls = target['annotation']['object']\n","    j = []\n","    if type(ls) == dict:\n","        if int(ls['difficult']) == 0:\n","            j.append(object_categories.index(ls['name']))\n","    else:\n","        for i in range(len(ls)):\n","            if int(ls[i]['difficult']) == 0:\n","                j.append(object_categories.index(ls[i]['name']))\n","    k = np.zeros(len(object_categories))\n","    k[j] = 1\n","    return torch.from_numpy(k)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"2MycNoV8cwq_","executionInfo":{"status":"ok","timestamp":1684030242277,"user_tz":300,"elapsed":1,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"outputs":[],"source":["transformations = transforms.Compose([transforms.Resize((300, 300)),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize(mean=mean, std=std)])\n","transformations_valid = transforms.Compose([transforms.Resize(330), \n","                                            transforms.CenterCrop(300), \n","                                            transforms.ToTensor(),\n","                                            transforms.Normalize(mean=mean, std=std)])"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"qR20ICwYZfib","executionInfo":{"status":"ok","timestamp":1684030246241,"user_tz":300,"elapsed":3292,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"outputs":[],"source":["dataset_train = PascalVOC_Dataset(data_dir,\n","                                  image_set='train', \n","                                  download=False, \n","                                  transform=transformations, \n","                                  target_transform=encode_labels)\n","dataset_aug = PascalVOC_Dataset(aug_dir,\n","                                  image_set='train', \n","                                  download=False, \n","                                  transform=transformations, \n","                                  target_transform=encode_labels)\n","\n","dataset_combined = ConcatDataset([dataset_train, dataset_aug])\n","\n","train_loader = DataLoader(dataset_combined, batch_size=batch_size, num_workers=2, shuffle=True)\n","\n","dataset_valid = PascalVOC_Dataset(data_dir, \n","                                  image_set='val', \n","                                  download=False, \n","                                  transform=transformations_valid, \n","                                  target_transform=encode_labels)\n","valid_loader = DataLoader(dataset_valid, batch_size=batch_size, num_workers=2)"]},{"cell_type":"code","source":["# for i in glob('/content/drive/MyDrive/cs444/project/da-fusion/aug/textual-inversion-0.5/pascal-0-8/*.png'):\n","#   im = Image.open(i)\n","#   filepath = '/content/drive/MyDrive/cs444/project/da-fusion/pascal-aug/pascal-0-8/VOCdevkit/VOC2012/JPEGImages/' + i.split('/')[-1].split('.')[0] + '.jpg'\n","#   im.save(filepath)\n"],"metadata":{"id":"AXN8YHf4sqI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for j in range(20): \n","#   for i in sorted(glob('/content/drive/MyDrive/cs444/project/da-fusion/pascal-aug/pascal-0-8/VOCdevkit/VOC2012/JPEGImages/*.jpg')):\n","#     num = i.split('/')[-1].split('-')[1]\n","#     name = i.split('/')[-1]\n","#     cat = object_categories[j]\n"," \n","#     if int(num) >= 8*j and int(num) < 8*j + 8:\n","#       root = ET.Element(\"annotation\")\n","#       ET.SubElement(root, \"folder\", name=\"folder\").text = \"VOC2012\"\n","#       ET.SubElement(root, \"filename\", name=\"filename\").text = name\n","\n","#       source = ET.SubElement(root, \"source\")\n","\n","#       ET.SubElement(source, \"database\", name=\"database\").text = \"The VOC2007 Database\"\n","#       ET.SubElement(source, \"annotation\", name=\"annotation\").text = \"PASCAL VOC2007\"\n","#       ET.SubElement(source, \"image\", name=\"image\").text = \"flickr\"\n","\n","#       size = ET.SubElement(root, \"size\")\n","#       ET.SubElement(size, \"width\", name=\"width\").text = '486'\n","#       ET.SubElement(size, \"height\", name=\"height\").text = '500'\n","#       ET.SubElement(size, \"depth\", name=\"depth\").text = '3'\n","\n","#       ET.SubElement(root, \"segmented\", name=\"segmented\").text = '0'\n","\n","#       obj = ET.SubElement(root, \"object\")\n","#       ET.SubElement(obj, \"name\", name=\"name\").text = cat\n","#       ET.SubElement(obj, \"pose\", name=\"pose\").text = 'Unspecified'\n","#       ET.SubElement(obj, \"truncated\", name=\"name\").text = '0'\n","#       ET.SubElement(obj, \"difficult\", name=\"difficult\").text = '0'\n","\n","#       tree = ET.ElementTree(root)\n","#       filename = '/content/drive/MyDrive/cs444/project/da-fusion/pascal-aug/pascal-0-8/VOCdevkit/VOC2012/Annotations/'+ name.split('.')[0] + '.xml'\n","#       print(filename)\n","#       tree.write(filename)\n","      "],"metadata":{"id":"IjX2za17ixcg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1NNfmBcIbaif"},"source":["## Define Model"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ZIcFhPiqbOBR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684030258488,"user_tz":300,"elapsed":8108,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}},"outputId":"3304fe08-53b6-4aa8-e2f7-3baa7722ba80"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 87.3MB/s]\n"]}],"source":["net = resnet18(pretrained=True)\n","net.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n","num_ftrs = net.fc.in_features\n","net.fc = torch.nn.Linear(num_ftrs, num_classes)\n","net = net.to(device)"]},{"cell_type":"markdown","metadata":{"id":"hSuc51ptcBFZ"},"source":["## Define Training Parameters"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"d0qXwNxrcDNa","executionInfo":{"status":"ok","timestamp":1684030258489,"user_tz":300,"elapsed":5,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"outputs":[],"source":["optimizer = optim.SGD([{'params': list(net.parameters())[:-1], 'lr': resnet_lr, 'momentum': 0.9},\n","                       {'params': list(net.parameters())[-1], 'lr': fc_lr, 'momentum': 0.9}])\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 12, eta_min=0, last_epoch=-1)\n","criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Tru2BAex5DNe","executionInfo":{"status":"ok","timestamp":1684030258489,"user_tz":300,"elapsed":4,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"outputs":[],"source":["def run_test(net, test_loader, criterion):\n","    correct = 0\n","    total = 0\n","    avg_test_loss = 0.0\n","    l = len(test_loader)\n","    with torch.no_grad():\n","        for _, (images, labels) in enumerate(test_loader):\n","            images, labels = images.to(device), labels.to(device)\n","            \n","            outputs = net(images)\n","            predictions = torch.argmax(outputs, dim=1)\n","            labels = torch.argmax(labels, dim=1)\n","            correct += torch.sum(predictions == labels)\n","            total += labels.size(0)\n","\n","    print(f'Accuracy of the network on the test images: {100 * correct / total:.2f} %')"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"eZGfBjDW4b9r","executionInfo":{"status":"ok","timestamp":1684030258490,"user_tz":300,"elapsed":4,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"outputs":[],"source":["def train(net, criterion, optimizer, num_epochs, print_freq = 100):\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        running_correct = 0.0\n","        running_total = 0.0\n","        start_time = time.time()\n","\n","        net.train()\n","\n","        for i, (images, labels) in enumerate(train_loader, 0):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            # Zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            # Get predicted results\n","            predicted = torch.argmax(outputs, dim=1)\n","            labels = torch.argmax(labels, dim=1)\n","\n","            # print statistics\n","            running_loss += loss.item()\n","\n","            # calculate accuracy\n","            running_total += labels.size(0)\n","            running_correct += (predicted == labels).sum().item()\n","\n","            # print every 2000 mini-batches\n","            if i % print_freq == (print_freq - 1):\n","                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n","                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n","                start_time = time.time()\n","\n","        # Run the run_test() function after each epoch\n","        net.eval()\n","        run_test(net, valid_loader, criterion)"]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"Wepg8apw21Kn","executionInfo":{"status":"ok","timestamp":1684030258490,"user_tz":300,"elapsed":4,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["train(net, criterion, optimizer, num_epochs=num_epochs)\n","\n","save_dir = os.path.join(ckpt_dir, 'da-fusion_8.pt')\n","torch.save(net.state_dict(), save_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2SfmfdZCh3Nm","outputId":"84cce12e-0549-44d1-8629-ba6d7058b8fa","executionInfo":{"status":"ok","timestamp":1684036947522,"user_tz":300,"elapsed":6683776,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[1,   100] loss: 160.830 acc: 13.12 time: 774.38\n","[1,   200] loss: 123.578 acc: 27.88 time: 752.78\n","Accuracy of the network on the test images: 46.51 %\n","[2,   100] loss: 102.454 acc: 46.25 time: 38.14\n","[2,   200] loss: 92.587 acc: 54.62 time: 39.14\n","Accuracy of the network on the test images: 64.35 %\n","[3,   100] loss: 79.701 acc: 62.31 time: 38.17\n","[3,   200] loss: 76.570 acc: 64.62 time: 39.27\n","Accuracy of the network on the test images: 67.78 %\n","[4,   100] loss: 70.331 acc: 67.66 time: 37.71\n","[4,   200] loss: 67.222 acc: 67.34 time: 38.37\n","Accuracy of the network on the test images: 68.07 %\n","[5,   100] loss: 63.378 acc: 70.41 time: 37.59\n","[5,   200] loss: 60.814 acc: 69.97 time: 39.33\n","Accuracy of the network on the test images: 68.61 %\n","[6,   100] loss: 57.874 acc: 72.50 time: 39.05\n","[6,   200] loss: 56.290 acc: 72.09 time: 38.48\n","Accuracy of the network on the test images: 68.92 %\n","[7,   100] loss: 54.609 acc: 72.94 time: 36.82\n","[7,   200] loss: 53.688 acc: 73.78 time: 37.73\n","Accuracy of the network on the test images: 69.86 %\n","[8,   100] loss: 50.229 acc: 75.59 time: 37.87\n","[8,   200] loss: 51.424 acc: 74.56 time: 37.73\n","Accuracy of the network on the test images: 70.58 %\n","[9,   100] loss: 48.205 acc: 75.12 time: 38.24\n","[9,   200] loss: 47.992 acc: 75.56 time: 36.67\n","Accuracy of the network on the test images: 71.15 %\n","[10,   100] loss: 45.355 acc: 77.34 time: 38.39\n","[10,   200] loss: 45.989 acc: 75.84 time: 36.11\n","Accuracy of the network on the test images: 70.74 %\n","[11,   100] loss: 43.602 acc: 76.44 time: 37.80\n","[11,   200] loss: 43.736 acc: 77.69 time: 37.06\n","Accuracy of the network on the test images: 71.39 %\n","[12,   100] loss: 41.974 acc: 78.22 time: 37.53\n","[12,   200] loss: 40.198 acc: 76.50 time: 37.57\n","Accuracy of the network on the test images: 72.45 %\n","[13,   100] loss: 39.895 acc: 77.19 time: 38.28\n","[13,   200] loss: 39.210 acc: 78.47 time: 37.68\n","Accuracy of the network on the test images: 71.85 %\n","[14,   100] loss: 37.072 acc: 78.50 time: 38.55\n","[14,   200] loss: 37.651 acc: 77.72 time: 37.93\n","Accuracy of the network on the test images: 71.85 %\n","[15,   100] loss: 36.044 acc: 78.19 time: 37.72\n","[15,   200] loss: 35.398 acc: 79.12 time: 36.71\n","Accuracy of the network on the test images: 72.16 %\n","[16,   100] loss: 34.233 acc: 79.81 time: 37.32\n","[16,   200] loss: 34.518 acc: 79.94 time: 38.17\n","Accuracy of the network on the test images: 73.43 %\n","[17,   100] loss: 32.076 acc: 80.00 time: 36.93\n","[17,   200] loss: 33.351 acc: 79.78 time: 37.69\n","Accuracy of the network on the test images: 72.68 %\n","[18,   100] loss: 31.191 acc: 80.03 time: 37.32\n","[18,   200] loss: 31.850 acc: 79.81 time: 37.19\n","Accuracy of the network on the test images: 72.18 %\n","[19,   100] loss: 30.091 acc: 80.69 time: 37.61\n","[19,   200] loss: 29.861 acc: 79.59 time: 35.27\n","Accuracy of the network on the test images: 72.27 %\n","[20,   100] loss: 28.162 acc: 81.16 time: 36.45\n","[20,   200] loss: 28.279 acc: 81.00 time: 37.21\n","Accuracy of the network on the test images: 72.78 %\n","[21,   100] loss: 27.128 acc: 81.25 time: 37.56\n","[21,   200] loss: 27.003 acc: 80.47 time: 36.29\n","Accuracy of the network on the test images: 73.14 %\n","[22,   100] loss: 25.012 acc: 81.44 time: 37.86\n","[22,   200] loss: 26.590 acc: 80.97 time: 37.44\n","Accuracy of the network on the test images: 72.73 %\n","[23,   100] loss: 24.027 acc: 81.72 time: 36.84\n","[23,   200] loss: 24.764 acc: 81.09 time: 38.36\n","Accuracy of the network on the test images: 72.20 %\n","[24,   100] loss: 22.535 acc: 81.62 time: 36.88\n","[24,   200] loss: 23.433 acc: 82.31 time: 37.21\n","Accuracy of the network on the test images: 73.35 %\n","[25,   100] loss: 21.333 acc: 82.12 time: 38.03\n","[25,   200] loss: 22.039 acc: 82.25 time: 37.05\n","Accuracy of the network on the test images: 73.16 %\n"]}]},{"cell_type":"code","source":["batch_size = 32\n","resnet_lr = 1e-6\n","fc_lr = 5e-4\n","num_epochs = 25"],"metadata":{"id":"Y4bizoQ2ZrBA","executionInfo":{"status":"ok","timestamp":1684036954672,"user_tz":300,"elapsed":118,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["train(net, criterion, optimizer, num_epochs=num_epochs)\n","\n","save_dir = os.path.join(ckpt_dir, 'da-fusion_8b.pt')\n","torch.save(net.state_dict(), save_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"B5uq3GnDY0cp","executionInfo":{"status":"error","timestamp":1684039538355,"user_tz":300,"elapsed":2580479,"user":{"displayName":"Rishabh Garg","userId":"00644947091830276805"}},"outputId":"02fc5133-6cc1-4747-c8af-86b2d9222d2a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[1,   100] loss: 20.884 acc: 82.28 time: 37.21\n","[1,   200] loss: 20.584 acc: 81.78 time: 37.02\n","Accuracy of the network on the test images: 73.60 %\n","[2,   100] loss: 19.172 acc: 82.28 time: 37.35\n","[2,   200] loss: 20.244 acc: 81.03 time: 38.13\n","Accuracy of the network on the test images: 73.06 %\n","[3,   100] loss: 18.173 acc: 82.19 time: 38.71\n","[3,   200] loss: 18.216 acc: 82.84 time: 38.16\n","Accuracy of the network on the test images: 73.64 %\n","[4,   100] loss: 16.958 acc: 82.56 time: 38.19\n","[4,   200] loss: 18.301 acc: 81.25 time: 37.52\n","Accuracy of the network on the test images: 73.06 %\n","[5,   100] loss: 16.168 acc: 82.66 time: 38.41\n","[5,   200] loss: 16.804 acc: 81.84 time: 36.27\n","Accuracy of the network on the test images: 73.31 %\n","[6,   100] loss: 15.094 acc: 82.97 time: 36.72\n","[6,   200] loss: 15.846 acc: 82.78 time: 37.57\n","Accuracy of the network on the test images: 73.43 %\n","[7,   100] loss: 14.704 acc: 82.09 time: 37.11\n","[7,   200] loss: 14.707 acc: 83.28 time: 37.80\n","Accuracy of the network on the test images: 73.60 %\n","[8,   100] loss: 13.959 acc: 82.50 time: 38.41\n","[8,   200] loss: 13.831 acc: 83.03 time: 38.63\n","Accuracy of the network on the test images: 73.36 %\n","[9,   100] loss: 13.008 acc: 83.28 time: 38.65\n","[9,   200] loss: 13.305 acc: 82.44 time: 37.73\n","Accuracy of the network on the test images: 73.55 %\n","[10,   100] loss: 12.433 acc: 81.91 time: 38.33\n","[10,   200] loss: 12.052 acc: 84.47 time: 36.77\n","Accuracy of the network on the test images: 73.12 %\n","[11,   100] loss: 10.975 acc: 83.00 time: 37.35\n","[11,   200] loss: 11.957 acc: 82.47 time: 36.74\n","Accuracy of the network on the test images: 73.50 %\n","[12,   100] loss: 10.898 acc: 82.25 time: 36.31\n","[12,   200] loss: 10.648 acc: 83.03 time: 37.23\n","Accuracy of the network on the test images: 73.47 %\n","[13,   100] loss: 10.455 acc: 82.66 time: 37.73\n","[13,   200] loss: 9.946 acc: 84.19 time: 36.33\n","Accuracy of the network on the test images: 72.97 %\n","[14,   100] loss: 9.166 acc: 83.53 time: 37.33\n","[14,   200] loss: 9.428 acc: 82.62 time: 36.49\n","Accuracy of the network on the test images: 73.28 %\n","[15,   100] loss: 8.562 acc: 83.22 time: 36.70\n","[15,   200] loss: 9.257 acc: 84.03 time: 37.77\n","Accuracy of the network on the test images: 73.14 %\n","[16,   100] loss: 8.473 acc: 83.91 time: 38.68\n","[16,   200] loss: 8.731 acc: 83.06 time: 38.63\n","Accuracy of the network on the test images: 73.26 %\n","[17,   100] loss: 7.977 acc: 84.16 time: 38.30\n","[17,   200] loss: 7.636 acc: 82.94 time: 35.39\n","Accuracy of the network on the test images: 73.31 %\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-10b75c8a1f08>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'da-fusion_8b.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-5b34652659cd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, criterion, optimizer, num_epochs, print_freq)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8gpDFo_BCNN","outputId":"ca310922-47cf-4996-d051-95fcf2592275","executionInfo":{"status":"ok","timestamp":1681675360781,"user_tz":300,"elapsed":2230025,"user":{"displayName":"Savya Khosla","userId":"05745142373296942590"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[1,   100] loss: 162.784 acc: 13.94 time: 2510.78\n","Accuracy of the network on the test images: 32.70 %\n","[2,   100] loss: 110.945 acc: 40.19 time: 38.42\n","Accuracy of the network on the test images: 55.32 %\n","[3,   100] loss: 90.052 acc: 53.69 time: 38.15\n","Accuracy of the network on the test images: 62.10 %\n","[4,   100] loss: 79.339 acc: 59.03 time: 39.18\n","Accuracy of the network on the test images: 64.28 %\n","[5,   100] loss: 71.841 acc: 63.97 time: 37.10\n","Accuracy of the network on the test images: 67.51 %\n","[6,   100] loss: 66.768 acc: 65.56 time: 37.70\n","Accuracy of the network on the test images: 68.13 %\n","[7,   100] loss: 62.867 acc: 67.38 time: 38.22\n","Accuracy of the network on the test images: 68.21 %\n","[8,   100] loss: 58.321 acc: 68.59 time: 37.98\n","Accuracy of the network on the test images: 68.73 %\n","[9,   100] loss: 55.473 acc: 69.81 time: 38.38\n","Accuracy of the network on the test images: 69.67 %\n","[10,   100] loss: 54.706 acc: 69.19 time: 37.57\n","Accuracy of the network on the test images: 69.74 %\n","[11,   100] loss: 52.067 acc: 70.25 time: 38.02\n","Accuracy of the network on the test images: 70.69 %\n","[12,   100] loss: 48.731 acc: 71.34 time: 37.00\n","Accuracy of the network on the test images: 70.86 %\n","[13,   100] loss: 48.809 acc: 70.62 time: 37.89\n","Accuracy of the network on the test images: 71.35 %\n","[14,   100] loss: 44.565 acc: 73.22 time: 38.33\n","Accuracy of the network on the test images: 71.41 %\n","[15,   100] loss: 44.324 acc: 72.69 time: 37.76\n","Accuracy of the network on the test images: 71.80 %\n","[16,   100] loss: 42.465 acc: 72.84 time: 37.32\n","Accuracy of the network on the test images: 71.84 %\n","[17,   100] loss: 40.415 acc: 73.09 time: 37.25\n","Accuracy of the network on the test images: 71.63 %\n","[18,   100] loss: 39.604 acc: 73.97 time: 38.10\n","Accuracy of the network on the test images: 72.08 %\n","[19,   100] loss: 37.339 acc: 75.38 time: 38.56\n","Accuracy of the network on the test images: 71.85 %\n","[20,   100] loss: 36.026 acc: 74.81 time: 37.71\n","Accuracy of the network on the test images: 72.01 %\n","[21,   100] loss: 34.183 acc: 75.50 time: 37.71\n","Accuracy of the network on the test images: 72.39 %\n","[22,   100] loss: 34.037 acc: 74.75 time: 38.10\n","Accuracy of the network on the test images: 72.33 %\n","[23,   100] loss: 32.170 acc: 75.50 time: 37.93\n","Accuracy of the network on the test images: 72.21 %\n","[24,   100] loss: 30.839 acc: 76.41 time: 37.90\n","Accuracy of the network on the test images: 71.87 %\n","[25,   100] loss: 29.877 acc: 76.28 time: 37.94\n","Accuracy of the network on the test images: 73.21 %\n"]}],"source":["train(net, criterion, optimizer, num_epochs=num_epochs)\n","\n","save_dir = os.path.join(ckpt_dir, 'baseline.pt')\n","torch.save(net.state_dict(), save_dir)"]},{"cell_type":"code","source":["base_model = torch.load('/content/drive/MyDrive/cs444/project/da-fusion.pt', map_location = 'cpu')"],"metadata":{"id":"1bhpJv2SiOfC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model = resnet18()\n","base_model.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n","num_ftrs = base_model.fc.in_features\n","base_model.fc = torch.nn.Linear(num_ftrs, 20)\n","base_model = base_model.to(device)"],"metadata":{"id":"NpxGqOwi3GDo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["state_dict = torch.load('/content/drive/MyDrive/cs444/project/da-fusion.pt', map_location = 'cpu')\n","\n","from collections import OrderedDict\n","new_state_dict = OrderedDict()\n","for k, v in state_dict.items():\n","  name = k[11:]\n","  new_state_dict[name] = v\n","\n","base_model.load_state_dict(new_state_dict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MsxHt29T2IyS","executionInfo":{"status":"ok","timestamp":1683876938979,"user_tz":300,"elapsed":123,"user":{"displayName":"Shrey Sarswat","userId":"00875473061557227049"}},"outputId":"06bfd520-bb3b-4aec-d666-487f4e7d48e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["torch.argmax(base_model(x[0][0].unsqueeze(0)), dim=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-HmRuzj2eHf","executionInfo":{"status":"ok","timestamp":1683876978837,"user_tz":300,"elapsed":276,"user":{"displayName":"Shrey Sarswat","userId":"00875473061557227049"}},"outputId":"beadb092-e2d3-48ad-8096-328f4eff0241"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([11])"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["run_test(base_model, iter(valid_loader), criterion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lHwzBszG2tsa","executionInfo":{"status":"ok","timestamp":1683879154566,"user_tz":300,"elapsed":1267078,"user":{"displayName":"Shrey Sarswat","userId":"00875473061557227049"}},"outputId":"3c2b888e-122e-4773-f589-e9513763383a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running: 0.005494505494505495\n","Running: 0.01098901098901099\n","Running: 0.016483516483516484\n","Running: 0.02197802197802198\n","Running: 0.027472527472527472\n","Running: 0.03296703296703297\n","Running: 0.038461538461538464\n","Running: 0.04395604395604396\n","Running: 0.04945054945054945\n","Running: 0.054945054945054944\n","Running: 0.06043956043956044\n","Running: 0.06593406593406594\n","Running: 0.07142857142857142\n","Running: 0.07692307692307693\n","Running: 0.08241758241758242\n","Running: 0.08791208791208792\n","Running: 0.09340659340659341\n","Running: 0.0989010989010989\n","Running: 0.1043956043956044\n","Running: 0.10989010989010989\n","Running: 0.11538461538461539\n","Running: 0.12087912087912088\n","Running: 0.12637362637362637\n","Running: 0.13186813186813187\n","Running: 0.13736263736263737\n","Running: 0.14285714285714285\n","Running: 0.14835164835164835\n","Running: 0.15384615384615385\n","Running: 0.15934065934065933\n","Running: 0.16483516483516483\n","Running: 0.17032967032967034\n","Running: 0.17582417582417584\n","Running: 0.1813186813186813\n","Running: 0.18681318681318682\n","Running: 0.19230769230769232\n","Running: 0.1978021978021978\n","Running: 0.2032967032967033\n","Running: 0.2087912087912088\n","Running: 0.21428571428571427\n","Running: 0.21978021978021978\n","Running: 0.22527472527472528\n","Running: 0.23076923076923078\n","Running: 0.23626373626373626\n","Running: 0.24175824175824176\n","Running: 0.24725274725274726\n","Running: 0.25274725274725274\n","Running: 0.25824175824175827\n","Running: 0.26373626373626374\n","Running: 0.2692307692307692\n","Running: 0.27472527472527475\n","Running: 0.2802197802197802\n","Running: 0.2857142857142857\n","Running: 0.29120879120879123\n","Running: 0.2967032967032967\n","Running: 0.3021978021978022\n","Running: 0.3076923076923077\n","Running: 0.3131868131868132\n","Running: 0.31868131868131866\n","Running: 0.3241758241758242\n","Running: 0.32967032967032966\n","Running: 0.33516483516483514\n","Running: 0.34065934065934067\n","Running: 0.34615384615384615\n","Running: 0.3516483516483517\n","Running: 0.35714285714285715\n","Running: 0.3626373626373626\n","Running: 0.36813186813186816\n","Running: 0.37362637362637363\n","Running: 0.3791208791208791\n","Running: 0.38461538461538464\n","Running: 0.3901098901098901\n","Running: 0.3956043956043956\n","Running: 0.4010989010989011\n","Running: 0.4065934065934066\n","Running: 0.41208791208791207\n","Running: 0.4175824175824176\n","Running: 0.4230769230769231\n","Running: 0.42857142857142855\n","Running: 0.4340659340659341\n","Running: 0.43956043956043955\n","Running: 0.44505494505494503\n","Running: 0.45054945054945056\n","Running: 0.45604395604395603\n","Running: 0.46153846153846156\n","Running: 0.46703296703296704\n","Running: 0.4725274725274725\n","Running: 0.47802197802197804\n","Running: 0.4835164835164835\n","Running: 0.489010989010989\n","Running: 0.4945054945054945\n","Running: 0.5\n","Running: 0.5054945054945055\n","Running: 0.510989010989011\n","Running: 0.5164835164835165\n","Running: 0.521978021978022\n","Running: 0.5274725274725275\n","Running: 0.532967032967033\n","Running: 0.5384615384615384\n","Running: 0.5439560439560439\n","Running: 0.5494505494505495\n","Running: 0.554945054945055\n","Running: 0.5604395604395604\n","Running: 0.5659340659340659\n","Running: 0.5714285714285714\n","Running: 0.5769230769230769\n","Running: 0.5824175824175825\n","Running: 0.5879120879120879\n","Running: 0.5934065934065934\n","Running: 0.5989010989010989\n","Running: 0.6043956043956044\n","Running: 0.6098901098901099\n","Running: 0.6153846153846154\n","Running: 0.6208791208791209\n","Running: 0.6263736263736264\n","Running: 0.6318681318681318\n","Running: 0.6373626373626373\n","Running: 0.6428571428571429\n","Running: 0.6483516483516484\n","Running: 0.6538461538461539\n","Running: 0.6593406593406593\n","Running: 0.6648351648351648\n","Running: 0.6703296703296703\n","Running: 0.6758241758241759\n","Running: 0.6813186813186813\n","Running: 0.6868131868131868\n","Running: 0.6923076923076923\n","Running: 0.6978021978021978\n","Running: 0.7032967032967034\n","Running: 0.7087912087912088\n","Running: 0.7142857142857143\n","Running: 0.7197802197802198\n","Running: 0.7252747252747253\n","Running: 0.7307692307692307\n","Running: 0.7362637362637363\n","Running: 0.7417582417582418\n","Running: 0.7472527472527473\n","Running: 0.7527472527472527\n","Running: 0.7582417582417582\n","Running: 0.7637362637362637\n","Running: 0.7692307692307693\n","Running: 0.7747252747252747\n","Running: 0.7802197802197802\n","Running: 0.7857142857142857\n","Running: 0.7912087912087912\n","Running: 0.7967032967032966\n","Running: 0.8021978021978022\n","Running: 0.8076923076923077\n","Running: 0.8131868131868132\n","Running: 0.8186813186813187\n","Running: 0.8241758241758241\n","Running: 0.8296703296703297\n","Running: 0.8351648351648352\n","Running: 0.8406593406593407\n","Running: 0.8461538461538461\n","Running: 0.8516483516483516\n","Running: 0.8571428571428571\n","Running: 0.8626373626373627\n","Running: 0.8681318681318682\n","Running: 0.8736263736263736\n","Running: 0.8791208791208791\n","Running: 0.8846153846153846\n","Running: 0.8901098901098901\n","Running: 0.8956043956043956\n","Running: 0.9010989010989011\n","Running: 0.9065934065934066\n","Running: 0.9120879120879121\n","Running: 0.9175824175824175\n","Running: 0.9230769230769231\n","Running: 0.9285714285714286\n","Running: 0.9340659340659341\n","Running: 0.9395604395604396\n","Running: 0.945054945054945\n","Running: 0.9505494505494505\n","Running: 0.9560439560439561\n","Running: 0.9615384615384616\n","Running: 0.967032967032967\n","Running: 0.9725274725274725\n","Running: 0.978021978021978\n","Running: 0.9835164835164835\n","Running: 0.989010989010989\n","Running: 0.9945054945054945\n","Running: 1.0\n","Accuracy of the network on the test images: 47.14 %\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_IOWKyXF8GJu"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1tnNexWUhj0CnOK410etU-i1g_ENvr5kn","timestamp":1683851527075}],"gpuType":"T4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}